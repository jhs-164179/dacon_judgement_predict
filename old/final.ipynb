{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier\n",
    "\n",
    "# from sklego.linear_model import DemographicParityClassifier, EqualOpportunityClassifier\n",
    "\n",
    "from utils_two import *\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train = pd.read_csv('./data/train.csv').drop('ID', axis=1)\n",
    "test = pd.read_csv('./data/test.csv').drop('ID', axis=1)\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 전처리\n",
    "cols = ['first_party', 'second_party', 'facts']\n",
    "shortword = re.compile(r'\\W*\\b\\w{1}\\b')\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "stopword = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "first_train, second_train, facts_train = preprocessing(train, cols, shortword, tokenizer, stopword, lemmatizer)\n",
    "first_test, second_test, facts_test = preprocessing(test, cols, shortword, tokenizer, stopword, lemmatizer)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,2))\n",
    "vec_facts = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_train = preprocessing_2(first_train, second_train, facts_train, vec, vec_facts)\n",
    "y_train = train['first_party_winner']\n",
    "X_test = preprocessing_2(first_test, second_test, facts_test, vec, vec_facts, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train 데이터>\n",
      "(2478, 211292) (2478,)\n",
      "\n",
      "<test 데이터>\n",
      "(1240, 211292)\n"
     ]
    }
   ],
   "source": [
    "print('<train 데이터>')\n",
    "print(X_train.shape, y_train.shape)\n",
    "print()\n",
    "print('<test 데이터>')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape after UnderSampling\n",
      "(1643, 211292) (1643,)\n",
      "====================\n",
      "Train target after UnderSampling\n",
      "first_party_winner\n",
      "0    829\n",
      "1    814\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불균형 문제 전처리(언더샘플링)\n",
    "X_nc, y_nc = NeighbourhoodCleaningRule(n_neighbors=3).fit_resample(X_train, y_train)\n",
    "print('Train Data Shape after UnderSampling')\n",
    "print(X_nc.shape, y_nc.shape)\n",
    "print('='*20)\n",
    "print('Train target after UnderSampling')\n",
    "print(y_nc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape\n",
      "(1232, 211292) (1232,)\n",
      "--------------------\n",
      "Train target\n",
      "first_party_winner\n",
      "0    622\n",
      "1    610\n",
      "Name: count, dtype: int64\n",
      "====================\n",
      "Validation Data Shape\n",
      "(411, 211292) (411,)\n",
      "--------------------\n",
      "Validation target\n",
      "first_party_winner\n",
      "0    207\n",
      "1    204\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train, Validation 분리\n",
    "Train_X, Val_X, Train_y, Val_y = train_test_split(X_nc, y_nc, test_size=.25, random_state=42, stratify=y_nc)\n",
    "print('Train Data Shape')\n",
    "print(Train_X.shape, Train_y.shape)\n",
    "print('-'*20)\n",
    "print('Train target')\n",
    "print(Train_y.value_counts())\n",
    "print('='*20)\n",
    "print('Validation Data Shape')\n",
    "print(Val_X.shape, Val_y.shape)\n",
    "print('-'*20)\n",
    "print('Validation target')\n",
    "print(Val_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6300617102556568\n",
      "[0.6746988  0.54878049 0.64634146 0.67073171 0.6097561 ]\n"
     ]
    }
   ],
   "source": [
    "Logistic = LogisticRegression(max_iter=500, random_state=42, C=10)\n",
    "Logistic.fit(Train_X, Train_y)\n",
    "# print(classification_report(Val_y, Logistic.predict(Val_X)))\n",
    "cv_score = cross_val_score(Logistic, Val_X, Val_y)\n",
    "print(cv_score.mean())\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic = LogisticRegression(max_iter=500, random_state=42)\n",
    "Logistic.fit(Train_X, Train_y)\n",
    "# print(classification_report(Val_y, Logistic.predict(Val_X)))\n",
    "cv_score = cross_val_score(Logistic, Val_X, Val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6349985307081988\n",
      "[0.65060241 0.54878049 0.65853659 0.67073171 0.64634146]\n"
     ]
    }
   ],
   "source": [
    "print(cv_score.mean())\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "tr_df = pd.DataFrame(X_nc)\n",
    "tr_df['target'] = y_nc\n",
    "tr_df\n",
    "\n",
    "oof_scores = []\n",
    "models = []\n",
    "pred_lst = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "n_iter = 0\n",
    "for train_idx, val_idx in kfold.split(tr_df, tr_df['target']):\n",
    "    tr_x = tr_df.drop('target', axis=1)\n",
    "    tr_y = tr_df['target']\n",
    "\n",
    "    n_iter+=1\n",
    "    model = LogisticRegression(max_iter=500, random_state=42)\n",
    "    models.append(model)\n",
    "    model.fit(tr_x.iloc[train_idx], tr_y.iloc[train_idx])\n",
    "    pred = model.predict(X_test)\n",
    "    pred_lst.append(pred)\n",
    "    score = acc(tr_y.iloc[val_idx], model.predict(tr_x.iloc[val_idx]))\n",
    "    oof_scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_res = pred_lst[0]+pred_lst[1]+pred_lst[2]+pred_lst[3]+pred_lst[4]\n",
    "\n",
    "res = np.where(pr_res>=3,1,0)\n",
    "submission['first_party_winner'] = res\n",
    "submission.to_csv('oof_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68       207\n",
      "           1       0.68      0.65      0.66       204\n",
      "\n",
      "    accuracy                           0.67       411\n",
      "   macro avg       0.67      0.67      0.67       411\n",
      "weighted avg       0.67      0.67      0.67       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temd = PassiveAggressiveClassifier(random_state=42)\n",
    "temd.fit(Train_X, Train_y)\n",
    "print(classification_report(Val_y, temd.predict(Val_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       207\n",
      "           1       0.62      0.75      0.68       204\n",
      "\n",
      "    accuracy                           0.65       411\n",
      "   macro avg       0.66      0.65      0.65       411\n",
      "weighted avg       0.66      0.65      0.65       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temd = SGDClassifier(random_state=42)\n",
    "temd.fit(Train_X, Train_y)\n",
    "print(classification_report(Val_y, temd.predict(Val_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.67       207\n",
      "           1       0.66      0.61      0.64       204\n",
      "\n",
      "    accuracy                           0.65       411\n",
      "   macro avg       0.65      0.65      0.65       411\n",
      "weighted avg       0.65      0.65      0.65       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temd = RidgeClassifier(random_state=42)\n",
    "temd.fit(Train_X, Train_y)\n",
    "print(classification_report(Val_y, temd.predict(Val_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('Ridge', RidgeClassifier(random_state=42)),\n",
    "    ('SGD', SGDClassifier(random_state=42)),\n",
    "    ('PA', PassiveAggressiveClassifier(random_state=42))\n",
    "]\n",
    "Stack = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(max_iter=500, random_state=42),\n",
    "    cv=4\n",
    "    )\n",
    "Stack.fit(X_nc, y_nc)\n",
    "Stack_res = Stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['first_party_winner']=Stack_res\n",
    "submission.to_csv('stacking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission['first_party_winner'] = Logistic.predict(X_test)\n",
    "# submission.to_csv('logi_linear.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['first_party_winner'] = Logistic.predict(X_test)\n",
    "submission.to_csv('logi___2_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhs_crime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
